{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tid-wrNW11pW"
      },
      "source": [
        "# Load Depenency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ACtufjx41sXQ"
      },
      "outputs": [],
      "source": [
        "#Cleaned up Crypto Example\n",
        "from os import system\n",
        "import pandas as pd\n",
        "import requests\n",
        "import datetime as dt\n",
        "# from pytrials.client import ClinicalTrials\n",
        "import json\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "np.random.seed(10031975)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib import rcParams, cycler\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import AutoMinorLocator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#does some error handling\n",
        "\n",
        "\n",
        "import sys\n",
        "import csv\n",
        "maxInt = sys.maxsize\n",
        "\n",
        "while True:\n",
        "    # decrease the maxInt value by factor 10 \n",
        "    # as long as the OverflowError occurs.\n",
        "\n",
        "    try:\n",
        "        csv.field_size_limit(maxInt)\n",
        "        break\n",
        "    except OverflowError:\n",
        "        maxInt = int(maxInt/10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pytrials.utils import json_handler, csv_handler\n",
        "\n",
        "\n",
        "class ClinicalTrials:\n",
        "    \"\"\"ClinicalTrials API client\n",
        "\n",
        "    Provides functions to easily access the ClinicalTrials.gov API\n",
        "    (https://clinicaltrials.gov/api/)\n",
        "    in Python.\n",
        "\n",
        "    Attributes:\n",
        "        study_fields: List of all study fields you can use in your query.\n",
        "        api_info: Tuple containing the API version number and the last\n",
        "        time the database was updated.\n",
        "    \"\"\"\n",
        "\n",
        "    _BASE_URL = \"https://clinicaltrials.gov/api/\"\n",
        "    _INFO = \"info/\"\n",
        "    _QUERY = \"query/\"\n",
        "    _JSON = \"fmt=json\"\n",
        "    _CSV = \"fmt=csv\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.api_info = self.__api_info()\n",
        "\n",
        "    @property\n",
        "    def study_fields(self):\n",
        "        fields_list = json_handler(\n",
        "            f\"{self._BASE_URL}{self._INFO}study_fields_list?{self._JSON}\"\n",
        "        )\n",
        "        return fields_list[\"StudyFields\"][\"Fields\"]\n",
        "\n",
        "    def __api_info(self):\n",
        "        \"\"\"Returns information about the API\"\"\"\n",
        "        last_updated = json_handler(\n",
        "            f\"{self._BASE_URL}{self._INFO}data_vrs?{self._JSON}\"\n",
        "        )[\"DataVrs\"]\n",
        "        api_version = json_handler(f\"{self._BASE_URL}{self._INFO}api_vrs?{self._JSON}\")[\n",
        "            \"APIVrs\"\n",
        "        ]\n",
        "\n",
        "        return api_version, last_updated\n",
        "\n",
        "    def get_full_studies(self, search_expr, min_rnk=1, max_studies=100):\n",
        "        \"\"\"Returns all content for a maximum of 100 study records.\n",
        "\n",
        "        Retrieves information from the full studies endpoint, which gets all study fields.\n",
        "        This endpoint can only output JSON (Or not-supported XML) format and does not allow\n",
        "        requests for more than 100 studies at once.\n",
        "\n",
        "        Args:\n",
        "            search_expr (str): A string containing a search expression as specified by\n",
        "                `their documentation <https://clinicaltrials.gov/api/gui/ref/syntax#searchExpr>`_.\n",
        "            max_studies (int): An integer indicating the maximum number of studies to return.\n",
        "                Defaults to 50.\n",
        "\n",
        "        Returns:\n",
        "            dict: Object containing the information queried with the search expression.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: The number of studies can only be between 1 and 100\n",
        "        \"\"\"\n",
        "        if max_studies > 100 or max_studies < 1:\n",
        "            raise ValueError(\"The number of studies can only be between 1 and 100\")\n",
        "\n",
        "        req = f\"full_studies?expr={search_expr}&min_rnk={min_rnk}&max_rnk={max_studies+min_rnk-1}&{self._JSON}\"\n",
        "\n",
        "        full_studies = json_handler(f\"{self._BASE_URL}{self._QUERY}{req}\")\n",
        "\n",
        "        return full_studies\n",
        "\n",
        "    def get_study_fields(self, search_expr, fields, max_studies=50, min_rnk=1,fmt=\"csv\"):\n",
        "        \"\"\"Returns study content for specified fields\n",
        "\n",
        "        Retrieves information from the study fields endpoint, which acquires specified information\n",
        "        from a large (max 1000) studies. To see a list of all possible fields, check the class'\n",
        "        study_fields attribute.\n",
        "\n",
        "        Args:\n",
        "            search_expr (str): A string containing a search expression as specified by\n",
        "                `their documentation <https://clinicaltrials.gov/api/gui/ref/syntax#searchExpr>`_.\n",
        "            fields (list(str)): A list containing the desired information fields.\n",
        "            max_studies (int): An integer indicating the maximum number of studies to return.\n",
        "                Defaults to 50.\n",
        "            fmt (str): A string indicating the output format, csv or json. Defaults to csv.\n",
        "\n",
        "        Returns:\n",
        "            Either a dict, if fmt='json', or a list of records (e.g. a list of lists), if fmt='csv.\n",
        "            Both containing the maximum number of study fields queried using the specified search expression.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: The number of studies can only be between 1 and 1000\n",
        "            ValueError: One of the fields is not valid! Check the study_fields attribute\n",
        "                for a list of valid ones.\n",
        "            ValueError: Format argument has to be either 'csv' or 'json'\n",
        "        \"\"\"\n",
        "        if max_studies > 1000 or max_studies < 1:\n",
        "            raise ValueError(\"The number of studies can only be between 1 and 1000\")\n",
        "        elif not set(fields).issubset(self.study_fields):\n",
        "            raise ValueError(\n",
        "                \"One of the fields is not valid! Check the study_fields attribute for a list of valid ones.\"\n",
        "            )\n",
        "        else:\n",
        "            concat_fields = \",\".join(fields)\n",
        "            # req = f\"study_fields?expr={search_expr}&max_rnk={max_studies}&fields={concat_fields}\"\n",
        "            req = f\"study_fields?expr={search_expr}&min_rnk={min_rnk}&max_rnk={max_studies+min_rnk-1}&fields={concat_fields}\"\n",
        "            if fmt == \"csv\":\n",
        "                url = f\"{self._BASE_URL}{self._QUERY}{req}&{self._CSV}\"\n",
        "                return csv_handler(url)\n",
        "\n",
        "            elif fmt == \"json\":\n",
        "                url = f\"{self._BASE_URL}{self._QUERY}{req}&{self._JSON}\"\n",
        "                return json_handler(url)\n",
        "\n",
        "            else:\n",
        "                raise ValueError(\"Format argument has to be either 'csv' or 'json'\")\n",
        "\n",
        "    def get_study_count(self, search_expr):\n",
        "        \"\"\"Returns study count for specified search expression\n",
        "\n",
        "        Retrieves the count of studies matching the text entered in search_expr.\n",
        "\n",
        "        Args:\n",
        "            search_expr (str): A string containing a search expression as specified by\n",
        "                `their documentation <https://clinicaltrials.gov/api/gui/ref/syntax#searchExpr>`_.\n",
        "\n",
        "        Returns:\n",
        "            An integer\n",
        "\n",
        "        Raises:\n",
        "            ValueError: The search expression cannot be blank.\n",
        "        \"\"\"\n",
        "        if not set(search_expr):\n",
        "            raise ValueError(\"The search expression cannot be blank.\")\n",
        "        else:\n",
        "            req = f\"study_fields?expr={search_expr}&max_rnk=1&fields=NCTId\"\n",
        "            url = f\"{self._BASE_URL}{self._QUERY}{req}&{self._JSON}\"\n",
        "            returned_data = json_handler(url)\n",
        "            study_count = returned_data[\"StudyFieldsResponse\"][\"NStudiesFound\"]\n",
        "            return study_count\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"ClinicalTrials.gov client v{self.api_info[0]}, database last updated {self.api_info[1]}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oKv5xQg2hgJ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://clinicaltrials.gov/api/gui/ref/crosswalks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Disease 2 search for"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is for dymanic input of diease searching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# disease=input()\n",
        "# print(disease)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "disease = 'parkinson'\n",
        "\n",
        "#disease = 'depression'\n",
        "\n",
        "# disease = 'diabetes'\n",
        "\n",
        "# disease = 'tacs'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "hit mesh some day"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pull ONE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_DJC1iG4RSB"
      },
      "source": [
        "#Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#change this out to NAME\n",
        "\n",
        "ct = ClinicalTrials()\n",
        "infodf= (ct.get_full_studies(search_expr=disease, max_studies=5 ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(infodf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3662\n"
          ]
        }
      ],
      "source": [
        "number = print(infodf['FullStudiesResponse']['NStudiesFound'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "count = ct.get_study_count(search_expr=disease)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1-99 of 3662\n",
            "100-99 of 3662\n",
            "199-99 of 3662\n",
            "298-99 of 3662\n",
            "397-99 of 3662\n",
            "496-99 of 3662\n",
            "595-99 of 3662\n",
            "694-99 of 3662\n",
            "793-99 of 3662\n",
            "892-99 of 3662\n",
            "991-99 of 3662\n",
            "1090-99 of 3662\n",
            "1189-99 of 3662\n",
            "1288-99 of 3662\n",
            "1387-99 of 3662\n",
            "1486-99 of 3662\n",
            "1585-99 of 3662\n",
            "1684-99 of 3662\n",
            "1783-99 of 3662\n",
            "1882-99 of 3662\n",
            "1981-99 of 3662\n",
            "2080-99 of 3662\n",
            "2179-99 of 3662\n",
            "2278-99 of 3662\n",
            "2377-99 of 3662\n",
            "2476-99 of 3662\n",
            "2575-99 of 3662\n",
            "2674-99 of 3662\n",
            "2773-99 of 3662\n",
            "2872-99 of 3662\n",
            "2971-99 of 3662\n",
            "3070-99 of 3662\n",
            "3169-99 of 3662\n",
            "3268-99 of 3662\n",
            "3367-99 of 3662\n",
            "3466-99 of 3662\n",
            "3565-99 of 3662\n"
          ]
        }
      ],
      "source": [
        "# count = 3000\n",
        "start = 0\n",
        "end = count\n",
        "iter = 99 #number of studies to get at a time ( limited to 1000 )\n",
        "\n",
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "\n",
        "\n",
        "temp = pd.DataFrame()\n",
        "temp2 = pd.DataFrame()\n",
        "new_df = pd.DataFrame()\n",
        "\n",
        "array = {}\n",
        "array ['key'] = 'value'\n",
        "json_data = json.dumps(array)\n",
        "\n",
        "for i in range(1, count, iter):\n",
        "    # print(temp)\n",
        "    temp =ct.get_full_studies(\n",
        "        search_expr=disease,\n",
        "        max_studies=iter,\n",
        "        min_rnk=i,\n",
        "        \n",
        "        # fmt=\"csv\",\n",
        "        )\n",
        "    # print(count),\n",
        "    print(str(i) + \"-\" + str(iter) + \" of \" + str(count))\n",
        "    # print(temp2[0])\n",
        "    temp2 =  pd.json_normalize(temp)\n",
        "    # json_object = temp['FullStudiesResponse']\n",
        "    # array = temp['FullStudiesResponse']\n",
        "    # temp2 = pd.json_normalize(temp())\n",
        "    new_df = pd.concat([new_df, temp2])\n",
        " \n",
        "# https://clinicaltrials.gov/api/gui/demo/simple_full_study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "print(type(new_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_df.to_excel(r'data_raw.xlsx', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Object of type DataFrame is not JSON serializable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Volumes/Data_Backup/github/API_CT/api_ct_v5_full_json_download.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Volumes/Data_Backup/github/API_CT/api_ct_v5_full_json_download.ipynb#ch0000021?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdata2.json\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Volumes/Data_Backup/github/API_CT/api_ct_v5_full_json_download.ipynb#ch0000021?line=1'>2</a>\u001b[0m     json\u001b[39m.\u001b[39;49mdump(new_df, f, ensure_ascii\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, indent\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/da622/lib/python3.10/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/__init__.py?line=172'>173</a>\u001b[0m     iterable \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(skipkeys\u001b[39m=\u001b[39mskipkeys, ensure_ascii\u001b[39m=\u001b[39mensure_ascii,\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/__init__.py?line=173'>174</a>\u001b[0m         check_circular\u001b[39m=\u001b[39mcheck_circular, allow_nan\u001b[39m=\u001b[39mallow_nan, indent\u001b[39m=\u001b[39mindent,\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/__init__.py?line=174'>175</a>\u001b[0m         separators\u001b[39m=\u001b[39mseparators,\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/__init__.py?line=175'>176</a>\u001b[0m         default\u001b[39m=\u001b[39mdefault, sort_keys\u001b[39m=\u001b[39msort_keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\u001b[39m.\u001b[39miterencode(obj)\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/__init__.py?line=176'>177</a>\u001b[0m \u001b[39m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/__init__.py?line=177'>178</a>\u001b[0m \u001b[39m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/__init__.py?line=178'>179</a>\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/__init__.py?line=179'>180</a>\u001b[0m     fp\u001b[39m.\u001b[39mwrite(chunk)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py?line=435'>436</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCircular reference detected\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py?line=436'>437</a>\u001b[0m     markers[markerid] \u001b[39m=\u001b[39m o\n\u001b[0;32m--> <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py?line=437'>438</a>\u001b[0m o \u001b[39m=\u001b[39m _default(o)\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py?line=438'>439</a>\u001b[0m \u001b[39myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py?line=439'>440</a>\u001b[0m \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py?line=159'>160</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py?line=160'>161</a>\u001b[0m     \u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py?line=161'>162</a>\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py?line=162'>163</a>\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py?line=176'>177</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py?line=177'>178</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py?line=178'>179</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///Users/ryoung/opt/anaconda3/envs/da622/lib/python3.10/json/encoder.py?line=179'>180</a>\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mTypeError\u001b[0m: Object of type DataFrame is not JSON serializable"
          ]
        }
      ],
      "source": [
        "with open('data2.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(new_df, f, ensure_ascii=False, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# count = 3000\n",
        "start = 0\n",
        "end = count\n",
        "iter = 99 #number of studies to get at a time ( limited to 1000 )\n",
        "\n",
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "\n",
        "\n",
        "temp = pd.DataFrame()\n",
        "temp2 = pd.DataFrame()\n",
        "new_df = pd.DataFrame()\n",
        "\n",
        "temp = ct.get_full_studies(\n",
        "        search_expr='tacs',\n",
        "    #     fields=[\"NCTId\", \"Condition\", \"OfficialTitle\", \"BriefTitle\" , \"Acronym\" , \"StudyType\",\n",
        "    # \"InterventionType\",\"InterventionName\",\"InterventionOtherName\",\"InterventionDescription\",\"Phase\" ,\"StudyFirstSubmitDate\",\"LastUpdateSubmitDate\",\"CompletionDate\",\"OverallStatus\",\"BaselineMeasureTitle\",\"BaselineMeasureDescription\",\"BaselineMeasurementValue\",\"BriefSummary\"],\n",
        "        max_studies=iter,\n",
        "        min_rnk=5,\n",
        "        # fmt=\"csv\",\n",
        "        )\n",
        "# print(full_studies)\n",
        "# print(temp)\n",
        "\n",
        "    # temp2 =  pd.DataFrame.from_records(temp[1:])\n",
        "    # new_df = pd.concat([new_df, temp2])\n",
        "# with open('data.json', 'w', encoding='utf-8') as f:\n",
        "#     json.dump(temp, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# number = print(temp['FullStudiesResponse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_df.columns = [\"Index\",\"NCTId\", \"Condition\", \"OfficialTitle\", \"BriefTitle\" , \"Acronym\" , \"StudyType\",\n",
        "    \"InterventionType\",\"InterventionName\",\"InterventionOtherName\",\"InterventionDescription\",\"Phase\" ,\"StudyFirstSubmitDate\",\"LastUpdateSubmitDate\",\"CompletionDate\",\"OverallStatus\",\"BaselineMeasureTitle\",\"BaselineMeasureDescription\",\"BaselineMeasurementValue\",\"BriefSummary\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "'NStudiesFound': 3656,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# new_df\n",
        "new_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_df.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# temp = pd.DataFrame.from_records(api_pull_2[1:], columns=api_pull_2[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(temp.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# count = 3000\n",
        "start = 0\n",
        "end = count\n",
        "iter = 999 #number of studies to get at a time ( limited to 1000 )\n",
        "\n",
        "from random import seed\n",
        "from random import random\n",
        "\n",
        "\n",
        "\n",
        "temp = pd.DataFrame()\n",
        "temp2 = pd.DataFrame()\n",
        "new_df2 = pd.DataFrame()\n",
        "\n",
        "\n",
        "for i in range(1, count, iter):\n",
        "    # print(temp)\n",
        "    temp = ct.get_study_fields(\n",
        "        search_expr=disease,\n",
        "        fields=[\"NCTId\",\"IsFDARegulatedDrug\",\"IsFDARegulatedDevice\", \"IsUnapprovedDevice\", \"PrimaryOutcomeMeasure\", \"PrimaryOutcomeDescription\",\"PrimaryOutcomeTimeFrame\", \"SecondaryOutcomeMeasure\",\"SecondaryOutcomeDescription\", \"SecondaryOutcomeTimeFrame\",\"OtherOutcomeMeasure\"\n",
        ",\"OtherOutcomeDescription\",\"OtherOutcomeTimeFrame\",\"EligibilityCriteria\",\"StudyPopulation\",\"HealthyVolunteers\", \"ReferencePMID\", \"LocationCity\", \"LocationState\" , \"LocationFacility\"],\n",
        "        max_studies=iter,\n",
        "        min_rnk=i,\n",
        "        fmt=\"csv\",)\n",
        "    # print(temp2[0])\n",
        "    temp2 =  pd.DataFrame.from_records(temp[1:])\n",
        "    new_df2 = pd.concat([new_df2, temp2])\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_df2.columns = [\"index\", \"NCTId\",\"IsFDARegulatedDrug\",\"IsFDARegulatedDevice\", \"IsUnapprovedDevice\", \"PrimaryOutcomeMeasure\", \"PrimaryOutcomeDescription\",\"PrimaryOutcomeTimeFrame\", \"SecondaryOutcomeMeasure\",\"SecondaryOutcomeDescription\", \"SecondaryOutcomeTimeFrame\",\"OtherOutcomeMeasure\"\n",
        ",\"OtherOutcomeDescription\",\"OtherOutcomeTimeFrame\",\"EligibilityCriteria\",\"StudyPopulation\",\"HealthyVolunteers\", \"ReferencePMID\", \"LocationCity\", \"LocationState\" , \"LocationFacility\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# api_pull_2 = ct.get_study_fields(\n",
        "#     search_expr=\"Parkinson\",\n",
        "#     fields=[\"NCTId\"],\n",
        "#     max_studies=10,\n",
        "#     min_rnk=5,\n",
        "#     fmt=\"csv\",\n",
        "# )\n",
        "\n",
        "# # ClinicalTrials limits API queries to 1000 records\n",
        "# # Count of studies may be useful to build loops when you want to retrieve more than 1000 records\n",
        "\n",
        "\n",
        "\n",
        "# # Read the csv data in Pandas\n",
        "# import pandas as pd\n",
        "\n",
        "# temp = pd.DataFrame.from_records(api_pull_2[1:], columns=api_pull_2[0])\n",
        "# temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o2YXU2v4Flm"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Get the NCTId, Condition and Brief title fields from 500 studies related to Coronavirus and Covid, in csv format.\n",
        "# api_pull_1 = ct.get_study_fields(\n",
        "#     search_expr=\"Parkinson\",\n",
        "#     fields=[\"NCTId\", \"Condition\", \"OfficialTitle\", \"BriefTitle\" , \"Acronym\" , \"StudyType\",\n",
        "#     \"InterventionType\",\"InterventionName\",\"InterventionOtherName\",\"InterventionDescription\",\"Phase\" \n",
        "#     ,\"StudyFirstSubmitDate\",\"LastUpdateSubmitDate\",\"CompletionDate\",\"OverallStatus\",\"IsFDARegulatedDrug\",\"IsFDARegulatedDevice\",\"BriefSummary\"],\n",
        "#     max_studies=999,\n",
        "#     fmt=\"csv\",\n",
        "# )\n",
        "\n",
        "# # ClinicalTrials limits API queries to 1000 records\n",
        "# # Count of studies may be useful to build loops when you want to retrieve more than 1000 records\n",
        "\n",
        "\n",
        "\n",
        "# # Read the csv data in Pandas\n",
        "# import pandas as pd\n",
        "\n",
        "# df1=pd.DataFrame.from_records(api_pull_1[1:], columns=api_pull_1[0])\n",
        "\n",
        "# # \n",
        "# # df1 = pd.DataFrame.to_frame().reset_index()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYsPomag4Vzm",
        "outputId": "e5468a7b-b50d-4b27-f898-46e1c87ee989"
      },
      "outputs": [],
      "source": [
        "# api_pull_2 = ct.get_study_fields(\n",
        "#     search_expr=\"Parkinson\",\n",
        "#     fields=[\"NCTId\",\"IsFDARegulatedDrug\",\"IsFDARegulatedDevice\", \"IsUnapprovedDevice\", \"PrimaryOutcomeMeasure\", \"PrimaryOutcomeDescription\",\"PrimaryOutcomeTimeFrame\", \"SecondaryOutcomeMeasure\",\"SecondaryOutcomeDescription\", \"SecondaryOutcomeTimeFrame\",\"OtherOutcomeMeasure\"\n",
        "# ,\"OtherOutcomeDescription\",\"OtherOutcomeTimeFrame\",\"EligibilityCriteria\",\"StudyPopulation\",\"HealthyVolunteers\", \"ReferencePMID\", \"LocationCity\", \"LocationState\" , \"LocationFacility\"\n",
        "\n",
        "# ],\n",
        "#     max_studies=999,\n",
        "#     fmt=\"csv\",\n",
        "# )\n",
        "\n",
        "# # ClinicalTrials limits API queries to 1000 records\n",
        "# # Count of studies may be useful to build loops when you want to retrieve more than 1000 records\n",
        "\n",
        "# ct.get_study_count(search_expr=\"Parkinson\")\n",
        "\n",
        "# # Read the csv data in Pandas\n",
        "# import pandas as pd\n",
        "\n",
        "# df2 = pd.DataFrame.from_records(api_pull_2[1:], columns=api_pull_2[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ1K9Cgd4xOC"
      },
      "source": [
        "##cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(type(df1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF7TnjRu4X9G"
      },
      "outputs": [],
      "source": [
        "result = pd.merge(new_df, new_df2,  on='NCTId', how='outer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# result = result.loc[:,~result.columns.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# result.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# result.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "IMPORTANT - this just drops the second index column - monitor or watch for mismatch or if you change the number of elements that are pulled from the first api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = result.drop(result.columns[[20]], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phxa_Vqn5E5S"
      },
      "outputs": [],
      "source": [
        "result.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# result.columns.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dgre9uB-INsI"
      },
      "outputs": [],
      "source": [
        "# result.to_csv(r'data_raw.csv', index = False)\n",
        "result.to_excel(r'data_raw.xlsx', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/7x/knvg10qn19740t2kqn0qwy_40000gn/T/ipykernel_23201/2317721403.py:1: PerformanceWarning: \n",
            "your performance may suffer as PyTables will pickle object types that it cannot\n",
            "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['FullStudiesResponse.APIVrs', 'FullStudiesResponse.DataVrs',\n",
            "       'FullStudiesResponse.Expression', 'FullStudiesResponse.FullStudies'],\n",
            "      dtype='object')]\n",
            "\n",
            "  new_df.to_hdf('data_raw.h5', key='df', mode='w')\n"
          ]
        }
      ],
      "source": [
        "new_df.to_hdf('data_raw.h5', key='df', mode='w')  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# labels, levels = pd.factorize(result[\"Phase\"])  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAqtYjoTICny",
        "outputId": "2f809d6a-4257-4ef1-b5f8-e601695a8d57"
      },
      "outputs": [],
      "source": [
        "# fun_barplot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJgWIlIm47Cc",
        "outputId": "2ca52a69-39fc-4489-9cef-d3cff0685215"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HW2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
